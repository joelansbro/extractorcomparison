[
    {
        "title":"Application Performance Monitoring AWS Lambda Functions with Sentry",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://www.fullstackpython.com/img/headers/python-lambda-sentry.jpg",
        "content":"\nAmazon Web Services (AWS) Lambda is a usage-based\ncomputing infrastructure service that can execute\nPython 3 code. One of the challenges of this\nenvironment is ensuring efficient performance of your Lambda Functions.\nApplication performance monitoring (APM) is particularly useful in these\nsituations because you are billed based on how long you use the\nresources.\nIn this post we will install and configure\nSentry's APM that works via a\nLambda layer.\nNote that if you are looking for error monitoring rather than performance\nmonitoring, take a look at\nHow to Monitor Python Functions on AWS Lambda with Sentry\nrather than following this post.\nFirst steps with AWS Lambda\nA local development environment is not\nrequired to follow this tutorial because all of the coding and configuration\ncan happen in a web browser through the\nAWS Console.\nSign into your existing AWS account\nor sign up for a new account. Lambda\ngives you the first 1 million requests for free so that you can execute\nbasic applications without no or low cost.\n\nWhen you log into your account, use the search box to enter\n\"lambda\" and select \"Lambda\" when it appears to get to the right\npage.\n\nIf you have already used Lambda before, you will see your existing Lambda\nfunctions in a searchable table. We're going to create a new function so\nclick the \"Create function\" button.\n\nThe create function page will give you several options for building a\nLambda function.\n\nClick the \"Browse Serverless App Repository\" selection box, then choose\nthe \"hello-world-python3\" starter app from within the\n\"Public applications\" section.\n\nThe hello-world-python3 starter app details page should look something\nlike the following screen:\n\nFill in some example text such as \"test\" under IdentityNameParameter\nand click the \"Deploy\" button:\n\nThe function will now be deployed. As soon as it is ready we can\ncustomize it and test it out before adding Sentry to capture any errors\nthat occur during execution.\nGo back to the Lambda functions main page and select your new deployed\nstarter app from the list.\n\nFind the orange \"Test\" button with a down arrow next to it like you\nsee in the image below, and then click the down arrow. Select\n\"Configure Test Event\".\n\nFill in the Event name as \"FirstTest\" or something similar, then\npress the \"Create\" button at the bottom of the modal window.\nClick the \"Test\" button and it will run the Lambda function with\nthe parameters from that new test event. You should see something\nlike the following output:\nResponse\n\"value1\" Function Logs\nSTART RequestId: 62fa2f25-669c-47b7-b4e7-47353b0bd914 Version: $LATEST\nvalue1 = value1\nvalue2 = value2\nvalue3 = value3\nEND RequestId: 62fa2f25-669c-47b7-b4e7-47353b0bd914\nREPORT RequestId: 62fa2f25-669c-47b7-b4e7-47353b0bd914 Duration: 0.30 ms Billed Duration: 1 ms Memory Size: 128 MB Max Memory Used: 43 MB Init Duration: 1.34 ms\n\nRequest ID\n62fa2f25-669c-47b7-b4e7-47353b0bd914\n\nThe code was successfully executed, so let's add Sentry's performance\nmonitoring and test some code that uses it.\nPerformance monitoring with Sentry\nGo to Sentry.io's homepage.\n\nSign into your account or sign up for a new free account. You will be at\nthe main account dashboard after logging in or completing the Sentry sign\nup process.\nSelect \"Performance\" on the left navigation bar, it will take you to the\nperformance monitoring page.\n\nClick \"Start Setup\" then go back over to AWS Lambda to complete the\nsteps for adding Sentry's Python layer to your Lambda function.\nThe easiest way to add Sentry to Lambda for this application\nis to configure an\nAWS Lambda Layer\nwith the necessary dependency for Sentry. Sentry has concise\ndocumentation on adding via Lambda Layers\nso we will walk through that way to configure it and test it\nout.\nScroll down to the \"Layers\" section while in your Lambda\nfunction configuration. Click the \"Add a layer\" button\":\n\nIn the \"Add layer\" screen, select the \"Specify an ARN\" option.\n\nNow to specify the Amazon Resource Name (ARN), we need to use\nthe Sentry documentation to get the right configuration string.\nUS-East-1 is the oldest and most commonly-used region so I'll\nuse that here in this tutorial but you should check which one\nyou are in if you are not certain.\n\nCopy that value into the Lambda Layer configuration, like this:\n\nThen press the \"Add\" button. You now have the Sentry dependency\nin your environment so code that relies upon that library can be\nused in the Lambda function.\nTesting performance monitoring\nLet's change our Python code in the Lambda function and test out\nthe APM agent.\nMake sure you are signed into your Sentry account and go to\nthis specific AWS Lambda set up guide.\nYou will see a \"DSN string\" that we need to set as an environment\nvariable on AWS Lambda to finish our setup. Copy the string that\nmatches your project as shown on that page in the highlighted green\nsection:\n\nWe will\nuse environment variables on AWS Lambda\nto store and access values like this Sentry DSN key.\nGo into the Lambda console to create a new environment variable. To do\nthat, click the \"Configuration\" tab within Lambda like you see here:\n\nThen click \"Edit\" and add a new environment variable with the key of SENTRY_DSN\nand the value of the DSN string that you copied from the Sentry screen. \n\nClick the \"Save\" button and go back to your Lambda function's code editor.\nReplace the code in your Lambda function with the following code:\nimport json\nimport os\nimport sentry_sdk\nimport time\nfrom sentry_sdk.integrations.aws_lambda import AwsLambdaIntegration\nfrom sentry_sdk import start_transaction SENTRY_DSN = os.environ.get('SENTRY_DSN')\nsentry_sdk.init( dsn=SENTRY_DSN, traces_sample_rate=1.0,\n    integrations=[AwsLambdaIntegration()]\n)\n\nprint('Loading function')\n\n\ndef lambda_handler(event, context):\n    calc = 1000\n\n    # this is custom instrumentation, see docs: https://bit.ly/2WjT3AY\n    with start_transaction(op=\"task\", name=\"big calculation\"):\n        for i in range(1, 1000):\n            calc = calc * i\n\n    print(calc)\n    return event['key1']  # Echo back the first key value\n\nThe above code imports the Sentry dependencies, and then runs both\nautomatic instrumentation\nand custom instrumentation on the\ncode. Click the \"Deploy\" button and then \"Test\". The code will\nsuccessfully execute and when we go back to our Sentry performance\nmonitoring dashboard we will see some initial results, like this\nfollowing screenshot.\n\nLooks good, you have both the default and the specified transaction\nperformance recordings in the dashboard, and you can toggle between\nthem (or other transactions you record) through the user interface.\nWhat's Next?\nWe just wrote and executed a Python 3 function on AWS Lambda that\nused the basics of Sentry APM to get some initial performance\nmonitoring data.\nCheck out the AWS Lambda section for\nmore tutorials by other developers.\nFurther questions? Contact me on Twitter\n@fullstackpython\nor @mattmakai. I am also on GitHub with\nthe username mattmakai.\nSomething wrong with this post? Fork\nthis page's source on GitHub\nand submit a pull request.\n",
        "next_page_url":null,
        "url":"https://www.fullstackpython.com/blog/application-performance-monitoring-aws-lambda-functions-sentry.html",
        "domain":"www.fullstackpython.com",
        "excerpt":"Learn how to use Sentry Application Performance Monitoring on AWS Lambda. Great post on fullstackpython.com!",
        "word_count":1113,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Asynchronous Web Scraping With Python AIOHTTP",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1648740784197%2FacHwqvSOX.png%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng",
        "content":"Hey there 👋, welcome here! Having looked at Asynchronous Web Scraping With Python GRequests, today we are using a different approach as I promised; We are using aiohttp\nOpen that article in a new tab because I will be referencing to it.\nSo we shall be using two major modules and one comes with the standard python library. It is a library for building web-client and web-server using Python and asyncio. It is a Python 3’s built-in library. This means it’s already installed if you have Python 3. Since Python 3.5, it is convenient to work with asynchronous code.\nasyncio stands for Asynchronous Input-Output. This is a very powerful concept to use whenever you work IO. Interacting with the web or external APIs such as Telegram makes a lot of sense this way.\nLet's not waste time and import the necessary modules\nimport aiohttp\nimport asyncio\nfrom timeit import default_timer\nYou may want to pip install aiohttp before you continue if you don't have it.\nWe define the same and exact URLs we used in our synchronous file in this article;\nurls = ['https: 'https: 'https: 'https: 'https: 'https:\nNow create a normal function that has async pre-appended to it lie this; async def main(): and add the following code underneath which I will explain later on;\nThis function will help us fetch the HTTP Status responses and we shall later define a main() one that will await the results from this function and aid us in creating and running the event loop.\nasync def fetch_status(): start_time = default_timer() async with ClientSession() as session: for url in urls: async with session.get(url) as response: print(f\"[+] Getting Link [+] {url} === {response.status} \") time_elapsed = default_timer() - start_time print(\"It took --- {} seconds --- for all the links\"\n      .format(time_elapsed))\nIn order to have an asynchronous function, we use the async keyword. \ndefault_timer() : This will return the default time when executed.\nWe open a client session with a with keyword that automatically handles the opening & closure of the session for us and then we loop through the URLs to get the response status.\nWe later calculate the time that has elapsed in doing so.\nNow let's create the main() function since it is required and very essential and it will basically call fetch_status().\nasync def main(): await fetch_status()\nNow if everything is good, we create the event loop and run our file;\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\nTo run an async function (coroutine) you have to call it using an Event Loop. Event Loops: You can think of Event Loops as functions to run asynchronous tasks and callbacks, perform network IO operations, and run subprocesses.\nRunning the above script produces;\n\nAt the time of writing, I am using Python 3.10 and yours could be perfect (between 3.5-3-8) and you may not see those depreciation warnings above.\nBut if you don't want to see them when you run your file, you can add this on top;\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSo our entire file is;\nimport aiohttp\nimport asyncio\nfrom timeit import default_timer\nfrom aiohttp import ClientSession\nimport warnings\nwarnings.filterwarnings(\"ignore\") urls = ['https://nytimes.com', 'https://github.com', 'https://google.com', 'https://reddit.com', 'https://hashnode.com', 'https://producthunt.com'] async def fetch_status(): start_time = default_timer() async with ClientSession() as session: for url in urls: async with session.get(url) as response: print(f\"[+] Getting Link [+] {url} === {response.status} \") time_elapsed = default_timer() - start_time print(\"It took --- {} seconds --- for all the links\" .format(time_elapsed)) async def main(): await fetch_status()\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n\nThat's it! Find the GitHub repo here.\n📌 Read my first article here.\n📌 asyncio official docs\n📌 aiohttp official docs Once again, hope you learned something today from my little closet.\nPlease consider subscribing or following me for related content, especially about Tech, Python & General Programming.\nYou can show extra love by buying me a coffee to support this free content and I am also open to partnerships, technical writing roles, collaborations and Python-related training or roles.\n  📢 You can also follow me on Twitter : ♥ ♥ Waiting for you! 🙂\n ",
        "next_page_url":null,
        "url":"https://blog.octachart.com/asynchronous-web-scraping-with-python-aiohttp",
        "domain":"blog.octachart.com",
        "excerpt":"Hey there 👋, welcome here! Having looked at Asynchronous Web Scraping With Python GRequests, today we are using a different approach as I promised; We are using aiohttp Open that article in a new tab&hellip;",
        "word_count":671,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Automating Excel with Python Video Overview - Mouse Vs Python",
        "author":null,
        "date_published":"2022-03-29T12:30:27.000Z",
        "dek":null,
        "lead_image_url":null,
        "content":"In this tutorial, I will show you an overview of using OpenPyXL and Python to read and write Excel documents. You will also learn how to:\n\nStyle cells\nChange fonts\nCreate named styles\nUse pandas with Excel\nCombine pandas and OpenPyXL\nBasics of using XslxWriter\n\nThe code in this tutorial is based on code from my book, Automating Excel with Python:\n\nGumroad (eBook)\nLeanpub (eBook)\nAmazon (paperback)\n\n\n",
        "next_page_url":null,
        "url":"https://www.blog.pythonlibrary.org/2022/03/29/automating-excel-with-python-video-overview/",
        "domain":"www.blog.pythonlibrary.org",
        "excerpt":"In this tutorial, I will show you an overview of using OpenPyXL and Python to read and write Excel documents. You will also learn how to: Style cells",
        "word_count":67,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Best 15+ Machine Learning Cheat Sheets to Pin to Your Toilet Wall",
        "author":"Chris",
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://blog.finxter.com/wp-content/uploads/2020/06/image-8-1024x789.png",
        "content":"\nThis article compiles for you the 15 best cheat sheets in the web that help you get started with machine learning. If you’re short on time, here are the 15 direct PDF links (open in a new tab): Each cheat sheet link points directly to the PDF file. So don’t lose any more time, and start learning faster with these 15 ML cheat sheets. In the following video, I quickly describe you all 15 cheat sheets and their pros and cons: \n\n  (Article reading time: 12 minutes ||| Or watch the video)  Cheat sheets are the 80/20 principle applied to coding: learn 80% of the relevant material in 20% of the time.  If you love learning with cheat sheets, join my free cheat sheet academy:  This article compiles the list of all the best cheat sheets for machine learning. Are you a practitioner and want to move towards machine learning and data science? Are you a young data scientist just starting out with your career? Or are you a computer science student struggling to find a clear path of how to master the intimidating area of machine learning? Then check out these cheat sheets to make your life easier. ALL LINKS OPEN IN A NEW TAB! 😉 Supervised Learning (Afshine Amidi) This cheat sheet is the first part of a series of cheat sheets created for the Stanford Machine Learning Class. It gives you a short and concise introduction to supervised learning.  Topics include the following: Supervised learning notations,Linear regression, Classification, Logistic regression, Generalized linear models, Support vector machines, Generative learning, Gaussian discriminant analysis, Naive Bayes, Tree-based and ensemble methods, and General learning theory. Unsupervised Learning (Afshine Amidi) This cheat sheet is the second part of the introductory series for the Stanford Machine Learning Class. It provides a concise introduction to unsupervised learning.  You will learn about these topics: Expectation-maximization (EM), K-means clustering, Hierarchical clustering, Clustering assessment metrics, Principal component analysis, and Independent component analysis. Deep Learning (Afshine Amidi)  This is the third part of the cheat sheet series provided by the Stanford Machine Learning Class. The cheat sheet is packed with dense information about deep learning. This cheat sheet offers a promising kickstart into the hot topic of deep learning.  The cheat sheet addresses topics such as  Introduction to neural networks, Entropy, Convolutional neural networks, Recurrent neural networks, Reinforcement learning, and Control.  \nOf course, this covers only a subspace of the broad field of deep learning, but it will give you a short and effective start into this attractive area.  Machine Learning Tips and Tricks (Afshine Amidi) The fourth part of the cheat sheet series provided as part of the Stanford Machine Learning Class promises small tips and tricks in machine learning. Although the author calls it that way (“Tips and Tricks”), I believe this is merely an understatement. In reality, this cheat sheet gives you valuable insights from a highly-skilled practitioner in the field.  The topics are not only limited to  Metrics, Classification, Regression, Model selection, and Diagnostics. A must-read for upcoming data scientists. Probabilities and Statistics (Afshine Amidi) The fifth part of the cheat sheet series of the Stanford Machine Learning Class gives you a quick start (they call it a “refresher”) in the crucial area of probability theory and statistics. No matter in which field you will end up working, statistics will always help you on your path to becoming a machine learning professional. This refresher is definitely worth a read (and an investment of your printer ink).  Here are the topics addressed in this cheat sheet:  Introduction to probability and combinatorics, Conditional probability, Random variables, Joint distributions, and Parameter estimation. Get this cheat sheet now! Linear Algebra and Calculus (Afshine Amidi) Although the sixth part of the popular cheat sheet series of the Stanford Machine Learning Class does not sound too sexy, it teaches a fundamental area each machine learning professional knows well: linear algebra.   Do you struggle understanding this critical topic? Your lack of understanding will cost you weeks as soon as you start implementing practical machine learning algorithms. Simply put: you have to master linear algebra, there is no way around. So do it now and do it well. What are the precise topics included in this cheat sheet?  Standard matrix notation, Matrix operations, Matrix properties, and Matrix calculus (gradient operations). You see, it’s all about matrices. Before you even consider diving in practical libraries used in machine learning (such as Python’s numpy, check out my HUGE numpy tutorial), study this cheat sheet first. Comprehensive Stanford Master Cheat Sheet (Afshine Amidi) This cheat sheet comprises six cheat sheets of the Stanford Machine Learning Class. It is an awesome resource, packed with information in many important subfields in Machine Learning. I highly recommend downloading this resource and studying it a whole day. It will boost your machine learning skills in little time.  The widely distributed topics of this 16-page cheat sheet include  Supervised Learning,Unsupervised learning, Deep learning,Machine learning tips and tricks, Probabilities and statistics, and Linear algebra and calculus. Don’t lose any more time reading the rest of this article and download this cheat sheet. Thanks, Afshine, for this awesome resource! Data Science Cheat Sheet (Datacamp) The datacamp cheat sheets are always worth a look. However, I would recommend this cheat sheet only for absolute beginners in the field of data science. If you focus on learning core machine learning concepts and you already have some experience, please skip this cheat sheet. But if you are just starting out with data science and machine learning – and you want to use Python as your programming language – this 1-page data science cheat sheet is for you.  The basic topics of this cheat sheet are  Installing Python, Python variables and data types, Strings and string operations, Lists and list methods, and Basic numpy functionality (numpy is the Python library for basic linear algebra and matrix operations). Keras Cheat Sheet (Datacamp) This 1-page cheat sheet is worth your time if you are looking into the specialized machine learning tool Keras. I have not yet used Keras myself but it is considered to be the best abstraction layer for deep learning and neural networks.   Wikipedia defines Keras as follows.  “Keras is an open source neural network library written in Python. It is capable of running on top of TensorFlow, Microsoft Cognitive Toolkit, or Theano. Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular, and extensible”.  With such a broad applicability, I am so convinced, I will check out Keras after finishing this blog post. Will you, too? If you’re interested in Keras, feel free to watch this video and read the associated blog article on the income levels of Keras developers: \n\n The Keras Cheat Sheet addresses the following points (from a code-centric perspective). Basic usage, Data and data structures, Preprocessing, Multilayer perceptron, Convolutional neural networks, Recurrent neural networks, and Model training, inference, & fine-tuning. Deep Learning with Keras Cheat Sheet (RStudio)  Simply put: I love this cheat sheet. It’s about deep learning with the open-source neural network library Keras. It is visual, to the point, comprehensive, and understandable. I highly recommend checking out this cheat sheet! The 2-page cheat sheet gives you a quick overview of the Keras pipeline for deep learning. It shows you how to work with models (e.g. definition, training, prediction, fitting, and evaluation). Furthermore, it gives you a visual overview of how to access the diverse layers in the neural network. Finally, it provides a short but insightful example of the standard demo problem of handwriting recognition. Visual Guide to Neural Network Infrastructures (Asimov Institute) This 1-page visual guide gives you a quick overview of all the most common neural network infrastructures that you will find in the wild. The sheet showcases 27 different architectures. As a machine learning newbie, you will not get much out of this sheet. However, if you are a practitioner in the field of neural networks, you will like it.  The cheat sheet shows 27 neural network architectures including Perceptron, Feedforward, Radial basis network, Deep feedforward, Recurrent neural network, long / short term memory (LSTM), gated recurrent unit, Autoencoder, variational autoencoder, denoising autoencoder, sparse autoencoder, Markov chain, Hopfield network, Boltzmann machine, restricted Boltzmann machine, deep belief network, andFinally, deep convolutional network, deconvolutional network, deep convolutional inverse graphics network, generative adversarial network, liquid state machine, extreme learning machine, echo state network, deep residual network, kohonen network, support vector machine, and neural turing machine. Pheww, what a list! Skicit-Learn Python Cheat Sheet (Datacamp) Another 1-page PDF cheat sheet that gives you a headstart in Python’s library for machine learning scikit-learn. This library is the best single-CPU, general-purpose libraries for machine learning in Python. Python is the most popular programming language in the field of machine learning, so this cheat sheet gives you a lot of value. Get this cheat sheet if you use Python for machine learning.  The topics include  Basic functionality such as loading and preprocessing the training data, Creating the model, Model fitting, Prediction and inference, and Evaluation metrics such as classification metrics, regression metrics, clustering metrics, cross-validation, and model tuning. Be warned that these concepts are not explained in detail. It only shows how to use them in the skicit-learn library. Scikit-learn Cheat Sheet: Choosing the Right Estimator (Scikit-learn.org) This cheat sheet is so valuable – I cannot even describe it in words. Thanks, scikit-learn creators, for posting this awesome piece of art!   It helps you figure out which algorithm to use for which kind of problem. You simply follow the questions in the cheat sheet. As a result, you will reach the recommended algorithm for your problem at hand. This is why I love cheat sheets – they can deliver complex information in little time. The cheat sheet divides the estimators into four classes:  Classification, Clustering, Regression, and Dimensionality reduction.  Although those classes are not explored in depth, you will already know in which direction to look further. Of course, if you are already an experienced practitioner, the provided information may be too simplistic – but isn’t this true for every cheat sheet?  Build your own opinion now! (Do it.) Tensorflow Cheat Sheet (Altoros) Although this cheat sheet is not the most sophisticated one, it is still valuable being one of the few TensorFlow cheat sheets out there.   You know TensorFlow, don’t you? TensorFlow is one of the most popular Github projects and it’s created by Google. Its machine learning API is tailored to deep learning on a heterogeneous computing environment (including GPUs). Nowadays, if you push in the field of deep learning, there is no way you can avoid TensorFlow.  Get a first impression with this cheat sheet and then dive into Google’s TensorFlow system. By the way, you can also use Keras on top of TensorFlow as a more high-level abstraction layer. Check out the Keras cheat sheet described earlier. The cheat sheet gives you hints about  The correct installation method, Helper functions, The name of some important functions in TensorFlow, and Estimators. To be frank, I would not recommend learning TensorFlow with this cheat sheet. Why? Because it is not focused on education. Yet, I felt obliged to include the link because there are no better alternatives for TensorFlow. If you know a better resource, please let me know. Machine Learning Test Cheat Sheet (Cheatography)  Do you know cheatography? It’s like Wikipedia for cheat sheets. Everybody can submit cheat sheets (user-generated content).  After going through most machine learning cheat sheets at Cheatography, I found that this one will be most helpful for most of our readers. It is a well-structured overview of some important machine learning algorithms. It shows you that there are three common problems in machine learning: regression, clustering, and classification. It gives you the general steps for training a model. Finally, it glances over a collection of specific algorithms that you should know when starting out in the field of machine learning. Those are logistic regression, decision tree, random forest, k-means, naive Bayes, k nearest neighbors, and support vector machines. I know that it is only a first dip into the ocean. But if you are a beginner or intermediate machine learning practitioner, this may just be what you have looked for. Microsoft’s Machine Learning Algorithm Cheat Sheet (Azure)  This excellent cheat sheet provides you a quick overview of the most important algorithms and how they are interrelated. It’s a great way to gain an overview of the field of artificial intelligence and machine learning. Did you enjoy this collection of the best machine learning cheat sheets on the web? I recommend to download all sheets, print them and work through each of them. This will give you a first overview of the field of machine learning. Later, you can decide in which area to dive in further.  Bonus: Many hot machine learning systems (e.g. TensorFlow) require excellent Python programming skills. Do you know all the features, tips, and tricks of Python? If not, I recommend to check out this free Python cheat sheet email course.  The email course will not only provide you with 5 Python cheat sheets (80% of the learning in 20% of the time, remember?) but also with a constant stream of Python programming lectures. It’s 100% free, you can unsubscribe at any time, and I will not spam you. It’s pure value (and occasionally I will send you information about my books and courses). So check it out! Subscribe to Email Course **FREE** Best Python Cheat Sheet Python is at the core of machine learning today. It has the best library support for machine learning among all programming languages. So, to become a better ML engineer, you may need to study Python. What better way than to download a cheat sheet PDF?  This is the best single cheat sheet. It uses every inch of the page to deliver value and covers everything you need to know to go from beginner to intermediate. Topics covered include container types, conversions, modules, maths, conditionals and formatting to name a few. A highly recommended 2-page sheet! Best NumPy Cheat Sheet Here’s a quick download for you: I created this cheating sheet to explain some important NumPy concepts to my coding students. (Click to download PDF) NumPy is a widely used Python scientific computing package. It simplifies linear algebra, matrix computations, and speeds up data analysis. Knowing NumPy is a prerequisite for other Python packages like pandas or Scikit-Learn. Best Scikit-Learn Cheat Sheet  This Scikit-Learn cheat sheet from DataCamp will kick start your data science project by introducing you to the basic concepts of machine learning algorithms successfully. This cheat sheet is for those who have already started to learn Python packages and for those who would like to take a quick look to get a first idea of the basics for total beginners! Best Scipy Cheat Sheet  The cheat sheet is from DataCamp.com and is chock full of information for you to consume. You will learn to interact with Numpy and know which functions and methods to use for linear algebra and of course a help section. This is one I would hang behind my monitor behind the wall! Best Pandas Cheat Sheet  This one is from the pandas guys, so it makes sense that this is a comprehensive and inclusive cheat sheet. It covers the vast majority of what most pandas users will ever need to do to a DataFrame. Have you already used pandas for a little while? And are you looking to up your game? This is your cheat sheet! However, if you are newer to pandas and this cheat sheet is a bit overwhelming, don’t worry! You definitely don’t need to understand everything in this cheat sheet to get started. Where to Go From Here? Enough theory. Let’s get some practice! Coders get paid six figures and more because they can solve problems more effectively using machine intelligence and automation.  To become more successful in coding, solve more real problems for real people. That’s how you polish the skills you really need in practice. After all, what’s the use of learning theory that nobody ever needs? You build high-value coding skills by working on practical coding projects! Do you want to stop learning with toy projects and focus on practical code projects that earn you money and solve real problems for people? 🚀 If your answer is YES!, consider becoming a Python freelance developer! It’s the best way of approaching the task of improving your Python skills—even if you are a complete beginner. If you just want to learn about the freelancing opportunity, feel free to watch my free webinar “How to Build Your High-Income Skill Python” and learn how I grew my coding business online and how you can, too—from the comfort of your own home. Join the free webinar now! While working as a researcher in distributed systems, Dr. Christian Mayer found his love for teaching computer science students.\nTo help students reach higher levels of Python success, he founded the programming education website Finxter.com. He’s author of the popular programming book Python One-Liners (NoStarch 2020), coauthor of the Coffee Break Python series of self-published books, computer science enthusiast, freelancer, and owner of one of the top 10 largest Python blogs worldwide.\nHis passions are writing, reading, and coding. But his greatest passion is to serve aspiring coders through Finxter and help them to boost their skills. You can join his free email academy here.\n",
        "next_page_url":null,
        "url":"https://blog.finxter.com/machine-learning-cheat-sheets/",
        "domain":"blog.finxter.com",
        "excerpt":"This article compiles for you the 15 best cheat sheets in the web that help you get started with machine learning. If you’re short on time, here are the 15 direct PDF links (open in a new tab): Each&hellip;",
        "word_count":2907,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Getting started with PYTHON!!! #2.2 - Escape Sequence",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1648876267053%2FAeNT1GJZw.jpg%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng",
        "content":"Soham Sarkar\n\n\nWhat escape sequence actually is, types of escape sequence & how to use them.\n\n Before we start with our lesson, let us recall Blog 2.1 .\n\nWe leant about variables(x) which is a symbolic name used to store some value, how to assign a variable(x=5). Similarly, Identifier is a name given for some value.x=5\nprint(x)\n\nKeywords are pre-defined words which have pre-existent defination.global x=10 #global is a keyword here , this line signifies that x is a global variable.\nprint(x)\n\nLiterals is the user-defined inputs given to an identifier. Eg : a=1 (1 is a numeric literal)n=5 f=1.2 c=\"a\" s=\"Soham\" b=True   \n\n Now, let us start with our current topic, i.e, escape sequence.\nWhen we hear the term escape, the first thing that comes to our mind is going to a new place by exiting from an old place or getting out of something and entering a new domain by running away from previous statement . Similarly escape sequence is used to get out of a line and go to the next line or get away from a statement by a tab space. Python online compiler \n\\n (used for escaping to the nextline or newline)\nprint(\"Hello viewer \\n Welcome to my blog\")\nO/P\nHello viewer\nWelcome to my blog\n\n\n\\t (used for vertical tab space)\nprint(\"Do share my blog. \\t Thank You\")\nO/P\nDo share my blog.             Thank You\n\n\n \\v (used for horizontal tab space)\nprint(\"Do give feedback on my blog if it has been useful to you. \\v Thank You\")\nO/P\nDo give feedback on my blog if it has been useful to you.  \n                                                          Thank You\n\n\n\\xhhh (displays the character with the respective hexadecimal value)\nprint(\"\\x48\\x65\\x6c\\x6c\\x6f\\x20\\x57\\x6f\\x72\\x6c\\x64\\x21\")\nO/P\nHello World!\n\n\n\\ooo (displays the character with the respective octal value)\nprint(\"\\110\\145\\154\\154\\157\\40\\127\\157\\162\\154\\144\\41\")\nO/P\nHello World!\n\n\n\\ (is used to ignore the backslash and newline)\nprint(\"L1 \\\nNewline\")\nO/P\nL1 Newline\n\n\n\\' or \\\" (is used to print the single or double quote)\nprint(\"Hello \\' Viewer\\\" \")\nO/P\nHello ' Viewer\"\n\n\n\n",
        "next_page_url":null,
        "url":"https://sohoxic.hashnode.dev/getting-started-with-python-22-escape-sequence",
        "domain":"sohoxic.hashnode.dev",
        "excerpt":"Hello People, In this blog we'll talk about What escape sequence actually is, types of escape sequence & how to use them. Before we start with our lesson, let us recall Blog 2.1 . We leant about&hellip;",
        "word_count":2,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"How I Learned to Code",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Funsplash%2FnpxXWgQ33ZQ%2Fupload%2Fv1648720338076%2FC63mb383u.jpeg%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng",
        "content":"The tech world continues to positively impact society for good, sometimes pays well too and you want to be part of it. But how do you break into the tech space as a newbie and how do you master the numerous tech tools you have to use? \nIn this article, I will tell you a little bit about how I got into the tech space as a Data Scientist and am currently a CTO of an AI startup(Zummit Africa Inc.). Maybe my journey might inspire yours(time will tell). \nI was first introduced to IT when I got into university to read BSc. Information Technology. Even though i was enrolled in a course on IT, I found it difficult to catch up with my coursework. \nThe university way of teaching the course did not appeal to me much. I felt like I could never be a programmer.\nBut fortunately, before I quit trying to excel in the tech world, I got a friend(Emmanuel Ankrah) who has more experience in the industry. So, I spoke to him about my challenges and he introduced me to Python(An easy to learn yet powerful programming language). \nMy discovery of Python was timely and important because it was a time when Data Science was emerging as a field of Computer Science. They even called it \"the sexiest job of the 21st Century\" and I thought that was cool. I also realized that Data scientists used Python for most of their work. I quickly decided that I was going to be a Data Scientist with Python. \nBased on my friend's recommendations, I got the book \"Learning Python\" by Mark Lutz. I learned a lot from this book because it was comprehensive. After a month of intensive Python work, I felt like I was ready to build small projects.\nAfter learning Python my world opened. My interest in Data Science peaked. I went searching online for information and resources on Data Science. My search was fruitful and I got a few materials, some books, and courses on the subject.\nAs I learned more about Data Science, I was moved to want to build more applications and perform analyses on data. Building smart applications with an AI backend has always been my biggest interest and Data Science and AI are making that possible. My journey allowed me the opportunity to learn some important lessons that I will love to share with you. These lessons can be a valuable guide for you on your journey. This is perhaps the most important lesson that has changed my life. The tech industry emerged because of the need to solve complex problems. Problems are a necessary part of the human experience and to solve them is to enrich lives and create opportunities for us all.\nSo, to get good with programming you first need to learn to solve problems. So how do you solve problems? Well, it's easy, right? Just find solutions. Solutions can come from anywhere so you need to look everywhere. For programmers, that means searching for answers from places like Google or Stackoverflow, etc. We can also find answers from the real world(the non-Internet world).\nThere are solutions out there for every problem. Sometimes we can's find it but just because we can't find it doesn't mean it's not there. If we search long enough we will find it.\nRemember that the solutions you engineer should create value for people. No value means no problem solved.\n This is a very important lesson but is easy to miss. This is because of a disease known as Imposter Syndrome. This disease makes you feel like you don't know enough to start practicing or building projects. The only cure for this disease is to take the leap of faith and plunge in. \nMake no mistake, the only way you can discover just how much you know is by building projects or applying what you learn. \nYes! You heard right. You can't be a great programmer without going through the headache of failed projects and bugs(programming errors you face daily, some lasting for weeks). The fastest way to learn to code is to learn to accept the fact that you will make some mistakes and that is ok.\nBut like I said earlier, every problem has a solution. If you stick with it, you will find it. There is a lot you can figure out on your own as a programmer but you can move faster by building on the shoulders of giants; Other programmers who have done the work and fixed the challenges you are facing. We will all move faster if we build upon what others have done. Just remember to give credit for their work.\nSo, when you get stuck, ask for help. You will be surprised to know that most people are willing to help you.\n Sharing is growth. The fastest way to reinforce your knowledge is to share it with others. When you teach others, you are mostly teaching yourself. So, don't keep your journey to yourself, share it with someone. You will help yourself and make the world a better place.\n The best solutions are usually the simplest solutions. Keep this in mind when building your personal portfolio projects or creating projects for a company. The little things in programming can lead to big problems or great opportunities. The major source of bugs in programming is a lack of attention to details. Pay attention to the little things. \nThis article provided a roadmap for succeeding in the tech space. I hope my journey and the lessons learned will inspire your journey and accelerate your growth. \n",
        "next_page_url":null,
        "url":"https://boadzie.hashnode.dev/how-i-learned-to-code",
        "domain":"boadzie.hashnode.dev",
        "excerpt":"The tech world continues to positively impact society for good, sometimes pays well too and you want to be part of it. But how do you break into the tech space as a newbie and how do you master the&hellip;",
        "word_count":937,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"How to Monitor Python Functions on AWS Lambda with Sentry",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://www.fullstackpython.com/img/headers/python-lambda-sentry.jpg",
        "content":"\nAmazon Web Services (AWS) Lambda is a usage-based\ncompute service that can run Python 3 code. Errors\ncan happen in any environment you are running your application in, so\nit is necessary to have reliable monitoring in place\nto have visibility when a problem occurs.\nIn this post we will install and configure\nSentry's application monitoring\nservice that works specifically for code running on AWS Lambda.\nApplication Dependencies\nA local development environment is not\nrequired to follow this tutorial because all of the coding and configuration\ncan happen in a web browser through the\nAWS Console.\nThe example code can be copy and pasted from this blog post or you\ncan access it on GitHub under the\nFull Stack Python blog-post-examples\nrepository within the\nmonitor-python-aws-lambda-sentry directory.\nAccessing the AWS Lambda Service\nSign into your existing AWS account\nor sign up for a new account. Lambda\ngives you the first 1 million requests for free so that you can execute\nbasic applications without no or low cost.\n\nWhen you log into your account, use the search box to enter\n\"lambda\" and select \"Lambda\" when it appears to get to the right\npage.\n\nIf you have already used Lambda before, you will see your existing Lambda\nfunctions in a searchable table. We're going to create a new function so\nclick the \"Create function\" button.\n\nThe create function page will give you several options for starting a new\nLambda function.\n\nClick the \"Browse Serverless App Repository\" selection box, then choose\nthe \"hello-world-python3\" starter app from within the\n\"Public applications\" section.\n\nThe hello-world-python3 starter app details page should look something\nlike the following screen:\n\nFill in some example text such as \"test\" under IdentityNameParameter\nand click the \"Deploy\" button:\n\nThe function will now be deployed. As soon as it is ready we can\ncustomize it and test it out before adding Sentry to capture any errors\nthat occur during execution.\nTesting the starter Python app\nGo back to the Lambda functions main page and select your new deployed\nstarter app from the list.\n\nFind the orange \"Test\" button with a down arrow next to it like you\nsee in the image below, and then click the down arrow. Select\n\"Configure Test Event\".\n\nFill in the Event name as \"FirstTest\" or something similar, then\npress the \"Create\" button at the bottom of the modal window.\nClick the \"Test\" button and it will run the Lambda function with\nthe parameters from that new test event. You should see something\nlike the following output:\nResponse\n\"value1\" Function Logs\nSTART RequestId: 62fa2f25-669c-47b7-b4e7-47353b0bd914 Version: $LATEST\nvalue1 = value1\nvalue2 = value2\nvalue3 = value3\nEND RequestId: 62fa2f25-669c-47b7-b4e7-47353b0bd914\nREPORT RequestId: 62fa2f25-669c-47b7-b4e7-47353b0bd914 Duration: 0.30 ms Billed Duration: 1 ms Memory Size: 128 MB Max Memory Used: 43 MB Init Duration: 1.34 ms\n\nRequest ID\n62fa2f25-669c-47b7-b4e7-47353b0bd914\n\nThat means the test case was successful, but what happens even if there\nis a straightforward mistake in the code, such as trying to access an\nundeclared variable?\nGo into the code editor and you should see the starter code like this:\n\nUpdate the code with the new highlighted line, which tries to access\na fourth variable, which does not exist in the test configuration\nwe try to run it with.\nimport json print('Loading function') def lambda_handler(event, context): #print(\"Received event: \" + json.dumps(event, indent=2)) print(\"value1 = \" + event['key1']) print(\"value2 = \" + event['key2']) print(\"value3 = \" + event['key3'])\n print(\"value4 = \" + event['key4'])\n    return event['key1']  # Echo back the first key value\n    #raise Exception('Something went wrong')\n\nAfter adding that one new line of code, hit the \"Deploy\" button,\nthen the \"Test\" button. You should see some error output:\nResponse\n{ \"errorMessage\": \"'key4'\", \"errorType\": \"KeyError\", \"stackTrace\": [ [ \"/var/task/lambda_function.py\", 11, \"lambda_handler\", \"print(\\\"value4 = \\\" + event['key4'])\" ] ]\n} Function Logs\nSTART RequestId: a4e956bd-cce4-403e-b5e7-e95bc3ffa2cb Version: $LATEST\nvalue1 = value1\nvalue2 = value2\nvalue3 = value3\n'key4': KeyError\nTraceback (most recent call last): File \"/var/task/lambda_function.py\", line 11, in lambda_handler print(\"value4 = \" + event['key4'])\nKeyError: 'key4' END RequestId: a4e956bd-cce4-403e-b5e7-e95bc3ffa2cb\nREPORT RequestId: a4e956bd-cce4-403e-b5e7-e95bc3ffa2cb Duration: 0.81 ms Billed Duration: 1 ms Memory Size: 128 MB Max Memory Used: 43 MB Init Duration: 1.61 ms\n\nRequest ID\na4e956bd-cce4-403e-b5e7-e95bc3ffa2cb\n\nIt is obvious when we are working in the Console that an error just\noccurred. However, in most cases an error will happen sporadically\nwhich is why we need a monitoring system in place to catch and report\non those exceptions.\nAWS Lambda function monitoring with Sentry\nThe easiest way to add Sentry to Lambda for this application\nis to configure an\nAWS Lambda Layer\nwith the necessary dependency for Sentry. Sentry has concise\ndocumentation on addin gvia Lambda Layers\nso we will walk through that way to configure it and test it\nout.\nFirst, scroll down to the \"Layers\" section while in your Lambda\nfunction configuration. Click the \"Add a layer\" button\":\n\nIn the \"Add layer\" screen, select the \"Specify an ARN\" option.\n\nNow to specify the Amazon Resource Name (ARN), we need to use\nthe Sentry documentation to get the right configuration string.\nUS-East-1 is the oldest and most commonly-used region so I'll\nuse that here in this tutorial but you should check which one\nyou are in if you are not certain.\n\nCopy that value into the Lambda Layer configuration, like this:\n\nThen press the \"Add\" button. Now you have the Sentry dependency\nin your environment so code that relies upon that library can be\nused in the Lambda function.\nNext we need to go into the Sentry dashboard to create a project,\nget our unique identifer, and connect it to our Lambda function.\nSentry can be self-hosted or\nused as a cloud service through Sentry.io. We will\nuse the cloud hosted version because it is quicker than\nsetting up your own server as well as free for smaller projects.\nGo to Sentry.io's homepage.\n\nSign into your account or sign up for a new free account. You will be at\nthe main account dashboard after logging in or completing the Sentry sign\nup process.\nThere are no errors logged on our account dashboard yet, which is as\nexpected because we have not yet connected our account to our Lambda\nfunction.\nClick \"Projects\" on the left navigation bar, then \"Create Project\"\nin the top right corner.\nUnder \"Choose a Platform\", select \"Serverless\" and then \"AWS Lambda (Python)\"\nas shown below:\n\nDecide under what criteria it should send error information out of\nLambda. For this tutorial, we will have it send every exception.\nThen click the \"Create Project.\" button.\nYou can have Sentry handle the instrumentation automatically but\nwe will handle it manually for our function. On the next screen, Sentry\nwill provide you with your unique DSN string, which we will need for\nour function.\n\nTypically you will want to\nuse environment variables on AWS Lambda\nto store and access values like your Sentry key.\nCopy the contents of the Sentry DSN string, and go into the Lambda console\nto create a new environment variable. To do that, click the \"Configuration\"\ntab within Lambda like you see here:\n\nThen click \"Edit\" and add a new environment variable with the key of SENTRY_DSN\nand the value of the DSN string that you copied from the Sentry screen. \n\nClick the \"Save\" button and go back to your Lambda function code.\nUpdate your Lambda function with the following highlighted new lines of code\nto send errors to Sentry.\nimport json\nimport os\nimport sentry_sdk\nfrom sentry_sdk.integrations.aws_lambda import AwsLambdaIntegration SENTRY_DSN = os.environ.get('SENTRY_DSN')\nsentry_sdk.init(\n dsn=SENTRY_DSN,\n integrations=[AwsLambdaIntegration()]\n) print('Loading function') def lambda_handler(event, context): #print(\"Received event: \" + json.dumps(event, indent=2))\n    print(\"value1 = \" + event['key1'])\n    print(\"value2 = \" + event['key2'])\n    print(\"value3 = \" + event['key3'])\n    print(\"value4 = \" + event['key4'])\n    return event['key1']  # Echo back the first key value\n    #raise Exception('Something went wrong')\n\nClick the \"Deploy\" button and then \"Test\". The code will throw\nan error and when we go back to our Sentry dashboard we will\nsee it captured and viewable for further inspection.\n\nIt works! Next you will likely want to tune your exception reporting\ncriteria to make sure you get alerted to the right number of exceptions\nif you do not want to see all of them.\nWhat's Next?\nWe just wrote and executed a Python 3 function on AWS Lambda then\ncaptured the exception message into the Sentry logs. You can\nnow continue building out your Python code knowing that when something\ngoes wrong you will have full visibility on what happened.\nCheck out the AWS Lambda section for\nmore tutorials by other developers.\nFurther questions? Contact me on Twitter\n@fullstackpython\nor @mattmakai. I am also on GitHub with\nthe username mattmakai.\nSomething wrong with this post? Fork\nthis page's source on GitHub\nand submit a pull request.\n",
        "next_page_url":null,
        "url":"https://www.fullstackpython.com/blog/monitor-python-functions-aws-lambda-sentry.html",
        "domain":"www.fullstackpython.com",
        "excerpt":"Learn how to monitor your Python 3 functions on AWS Lambda using Sentry. Great post on fullstackpython.com!",
        "word_count":1445,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"How To Start Your Programming Journey !",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1648802176922%2Fch04QWI6T.jpg%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng",
        "content":"Sourav MandalYour browser does not support the audio element.\nHey There, I am Sourav Mandal, i am full stack web developer. i started my programming journey Before 4 Years and since last 4 months i started share my knowledge in Twitter.\nIn last 4 years i improve my programming skill by day by day. Through this Article i will share some knowledge that helps you to improve your programming skill.\n\nSELF LEARNING:\n\n\nMy first programming language is python. i learn python over a mobile and i collect all the resources form online. if you want to learn programming you don't need to join a institute because whatever you want all the resources available in online, you can collect them and learn form there.\nAnd you don't need a powerful machine to start programming, you just need a normal system. mainly you have to motivate yourself that you can Learn.\n\nYou have to decide that what programming language that you have to learn, fix that and start learning from today. \nFind the tutorial that you have to learn, set the routine that how much you have to learn in one day. practice more than you read. try to build various types of projects. \nWhen you start learning make sure to note every bigger and smaller things. you have to clear each and every concept, Don't think that any concept is useless because in future every little things can help you to fine out the way. If you learn programming from online or learning from an institute make sure that you are active in social media\nBecause there are so many content creator over there.They share very useful tips and tricks that can help you to learn.\nI suggest twitter because i personally use twitter and i think twitter is one of the best platform for learn programming. \nThanks for reading, I hope you enjoy this article, if you are interested in web development make sure to follow me in Twitter.\nmy twitter handle @souravWD ( if you have any doubt comment below )\n\n311",
        "next_page_url":null,
        "url":"https://souravwd.hashnode.dev/how-to-start-your-programming-journey",
        "domain":"souravwd.hashnode.dev",
        "excerpt":"Hey There, I am Sourav Mandal, i am full stack web developer. i started my programming journey Before 4 Years and since last 4 months i started share my knowledge in Twitter. In last 4 years i improve&hellip;",
        "word_count":2,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Python For Everyone",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://hashnode.com/post/cover/cl1hp6grb02icjvnv0d0o9t5h",
        "content":"Python is an open-source programming language created in the 1980s by Guido van Rossum to make programming easy and very near to human language. Python can be used for many tasks like \n\nAI (Machine Learning and Deep Learning)\ncreating custom scripts for daily tasks\nConduct Complex Statistics\nData analysis and data visualization.\n We have seen many programming languages with strict rules and syntax; without following these, we can't do anything. By the way, I am not saying Python doesn't follow the rules, but it has its own rules #syntax. But the best thing about Python No more Semi-colon Errors.\nIf we compare Python language with other languages like C++ and C#\n\nwe use brackets {} for defining the delimiters and scope; here, we use indentation\nmore English-like words instead of symbols.\n for i in range(0,100): if i % 2=0: print(i)\n\nThere are many IDE where you can write and execute instructions in Python. Some are as follows.\n\nVSCode\nSpyder\nAnaconda\nJupyter Notebook\nGoogle Colab\n\nMy personal recommendation is to use VSCode or Jupyter Notebookas offline IDE and Google Colab for online.\nSo, the above information was all about the introduction to Python programming language. In the following article, we shall start the coding implementation using Python from the very beginning. See you in the next post. Take care.\n",
        "next_page_url":null,
        "url":"https://hami.hashnode.dev/python-for-everyone",
        "domain":"hami.hashnode.dev",
        "excerpt":"Getting Started with Python",
        "word_count":218,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Quick Guide to making Rest API using Django",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1648750686118%2FWPPPV3DQZ.webp%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng",
        "content":"Hello there, in this article we will learn how to quickly make a CRUD RESTFul API in the Django rest framework. Few pre-requisite we assume that the reader knows python, very basics of Django, and have an understanding of MVC or MVT architecture\nSo first let's create a virtual environment, it is an optional step but is good practice to have project dependencies portable. Refer to Virtual Env guide to making one for this project.\nNow let's install Django after that DjangoRestFramework and create our project.\npip install django\npip install djangorestframework\nCreating Project in django\ndjango-admin startproject 'project_name'\n\ngo to the project directory\nCreate an app with the below command, one thing here is one project can have many apps and the ones we are using should be added in the settings.py file of our project inside INSTALLED_APPS[]. So we need to add our 'app_name' and 'rest_framework' to the list.\npython manage.py startapp 'app_name'\n\nWe have our project ready now and the app inside as well. Open it in any IDE and go to the models.py file of your app. Quick overview it has the structure of our model(s) which is our database representation of the entity.\nHere is guide to make model quickly and refer this for more insight. Below is a sample model for your reference\nMarvel/Spiderverse/models.py\nfrom django.db import models class Spiderverse(models.Model): name= models.CharField(max_length = 50) description= models.TextField()\nNow we need a Serializer class for our model, we can create it from scratch for each field of the model and have separate update() and create() methods overridden or we could just use model serializers to make things easy and quick.\nWhy do we need Serializers in the first place?\nin simple terms, serializer return data into python native datatypes from complex datatypes like Queryset, and native data can be easily converted to JSON or XML, etc which makes data representation easy.\nMarvel/Spiderverse/serializers.py\nfrom rest_framework import serializers\nfrom .models import Spiderverse class SpiderSerializers(serializers.ModelSerializer): class Meta: model = Spiderverse fields = \"__all__\"\nNow we will move towards creating views for our mini project, views will have most of our logic of CRUD. We will use here class-based views that reuse already created code functionality from generics classes and mixins that have commonly used logic. \nFor example, our code logic for get() and post() method which we can overwrite using mixins that will be common for every model is already implemented in generics classes we just have inherited that code. Below is the implementation of get() post() method if we use mixin for creating and listing all the elements of the class. \nclass SpiderverseList(mixins.ListModelMixin, mixins.CreateModelMixin, generics.GenericAPIView): queryset = Spiderverse.objects.all() serializer_class = SpiderSerializer def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs)\nNow if we use generics.ListCreateAPIView, instead of the mixins we used above, generics have already implemented these methods for us, we will just inherit the class and assign modelserializer and queryset. \nMarvel/Spiderverse/views.py \nfrom .models import Spiderverse from .serializers import SpiderSerializer from rest_framework import generics class SpiderverseList(generics.ListCreateAPIView): queryset = Spiderverse.objects.all() serializer_class = SpiderSerializers class SpiderverseDetail(generics.RetrieveUpdateDestroyAPIView): \n    queryset = Spiderverse.objects.all()\n    serializer_class = SpiderSerializers\nfor Retrieve, Update, and Delete part of our implementation we used generics.RetrieveUpdateDestroyAPIView class. Now the final thing is to set up URLs for each view in urls file. Add the application to the projects urls.py file. \nMarvel/urls.py \nfrom django.urls import path, include urlpatterns = [path('', include('Spiderverse.urls'))]\nand below code is for our app.\nMarvel/Spiderverse/urls.py \nfrom django.urls import path from .views import SpiderverseList, SpiderverseDetail urlpatterns = [ path('spider/', SpiderverseList.as_view()), path('spider/<int:pk>/', SpiderverseDetail.as_view()) ]\nso this is it below our mini RESTFul API is ready and we can perform operations using given URLs and parameters. I have used postman for this example you can use any frontend you have, django forms or curl, etc options.\nLast but not least, Do not forget to make migrations to make a database for our model.\npython manage.py makemigrations\npython manage.py migrate\nRefer django and django restframwrok for a detailed guide.\n",
        "next_page_url":null,
        "url":"https://r4hu1s0n7.hashnode.dev/quick-guide-to-making-rest-api-using-django",
        "domain":"r4hu1s0n7.hashnode.dev",
        "excerpt":"Make RESTFul API before your food gets delivered...",
        "word_count":665,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Using Django & AssemblyAI for More Accurate Twilio Call Transcriptions",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://www.fullstackpython.com/img/headers/django-assemblyai.jpg",
        "content":"\nRecording phone calls\nwith one or more participants is easy with\nTwilio's Programmable Voice API,\nbut the speech-to-text accuracy can be poor, especially for transcription\nof words from niche domains such as healthcare and engineering.\nAssemblyAI's API for transcription\nprovides much higher accuracy by default and through optional keyword lists.\naccuracy for recordings. \nIn this tutorial, we'll record an outbound Twilio call recording to AssemblyAI's\nAPI to get significantly more accurate speech-to-text output.\nTutorial Prerequisites\nEnsure you have Python 3 installed, because Python 2 reached its\nend-of-life at the beginning of 2020 and is no longer supported.\nPreferrably, you should have\nPython 3.7 or greater installed\nin your development environment.\nThis tutorial will also use:\nWe will use the following dependencies to complete this\ntutorial: All code in this blog post is available open source under the MIT license\non GitHub under the\ndjango-accurate-twilio-voice-transcriptions directory of the blog-code-examples repository.\nUse the source code as you desire for your own projects.\nConfiguring our development environment\nChange into the directory where you keep your Python\nvirtual environments.\nCreate a new virtualenv for this project using the following\ncommand.\nStart the Django project by creating a new\nvirtual environment\nusing the following command. I recommend using a separate directory\nsuch as ~/venvs/ (the tilde is a shortcut for your user's home\ndirectory) so that you always know where all your virtualenvs are\nlocated.\npython3 -m venv ~/venvs/djtranscribe\n\nActivate the virtualenv with the activate shell script:\nsource ~/venvs/djtranscribe/bin/activate\n\nAfter the above command is executed, the command prompt will\nchange so that the name of the virtualenv is prepended to the\noriginal command prompt format, so if your prompt is just\n$, it will now look like the following: Remember, you have to activate your virtualenv in every new terminal\nwindow where you want to use dependencies in the virtualenv.\nWe can now install the Django\npackage into the activated but otherwise empty virtualenv.\npip install django==3.1.3 requests==2.24.0 twilio==6.45.2\n\nLook for output similar to the following to confirm the appropriate\npackages were installed correctly from PyPI.\n(djtranscribe) $ pip install django==3.1.3 requests==2.24.0 twilio=6.45.2\npip install django requests twilio\nCollecting django Downloading Django-3.1.3-py3-none-any.whl (7.8 MB) |████████████████████████████████| 7.8 MB 2.6 MB/s Collecting requests Using cached requests-2.24.0-py2.py3-none-any.whl (61 kB)\nCollecting twilio Downloading twilio-6.47.0.tar.gz (460 kB) |████████████████████████████████| 460 kB 19.6 MB/s Collecting sqlparse>=0.2.2 Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB) |████████████████████████████████| 42 kB 4.8 MB/s Collecting pytz Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB) |████████████████████████████████| 509 kB 31.0 MB/s Collecting asgiref<4,>=3.2.10 Downloading asgiref-3.3.0-py3-none-any.whl (19 kB)\nCollecting chardet<4,>=3.0.2 Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\nCollecting idna<3,>=2.5 Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\nCollecting certifi>=2017.4.17 Using cached certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\nCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB) |████████████████████████████████| 127 kB 24.5 MB/s Collecting six Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting PyJWT>=1.4.2 Using cached PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nUsing legacy 'setup.py install' for twilio, since package 'wheel' is not installed.\nInstalling collected packages: sqlparse, pytz, asgiref, django, chardet, idna, certifi, urllib3, requests, six, PyJWT, twilio Running setup.py install for twilio ... done\nSuccessfully installed PyJWT-1.7.1 asgiref-3.3.0 certifi-2020.6.20 chardet-3.0.4 django-3.1.3 idna-2.10 pytz-2020.4 requests-2.24.0 six-1.15.0 sqlparse-0.4.1 twilio-6.47.0 urllib3-1.25.11\n\nWe can get started coding the application now that we have all of our\nrequired dependencies installed.\nStarting our Django project\nLet's begin coding our application.\nWe can use the Django django-admin tool to create\nthe boilerplate code structure to get our project started.\nChange into the directory where you develop your applications. For\nexample, I typically use /Users/matt/devel/py/ for all of my\nPython projects. Then run the following command to start a Django\nproject named djtranscribe:\ndjango-admin.py startproject djtranscribe\n\nNote that in this tutorial we are using the same name for both the\nvirtualenv and the Django project directory, but they can be\ndifferent names if you prefer that for organizing your own projects.\nThe django-admin command creates a directory named djtranscribe\nalong with several subdirectories that you should be familiar with\nif you have previously worked with Django.\nChange directories into the new project. Create a new Django app within djtranscribe named caller.\npython manage.py startapp caller\n\nDjango will generate a new folder named caller in the project.\nWe should update the URLs so the app is accessible before we write\nour views.py code.\nOpen djtranscribe/djtranscribe/urls.py. Add the highlighted\nlines so that URL resolver will check the caller app\nfor additional routes to match with URLs that are requested of\nthis Django application.\n# djtranscribe/djtranscribe/urls.py\nfrom django.conf.urls import include\nfrom django.contrib import admin\nfrom django.urls import path urlpatterns = [\n path('', include('caller.urls')),\n    path('admin/', admin.site.urls),\n]\n\nSave djtranscribe/djtranscribe/urls.py and open\ndjtranscribe/djtranscribe/settings.py.\nAdd the caller app to settings.py by inserting\nthe highlighted line:\n# djtranscribe/djtranscribe/settings.py\n# Application definition INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles',\n 'caller',\n]\n\nMake sure you change the default DEBUG and SECRET_KEY\nvalues in settings.py before you deploy any code to production. Secure\nyour app properly with the information from the Django\nproduction deployment checklist\nso that you do not add your project to the list of hacked applications\non the web.\nSave and close settings.py.\nNext change into the djtranscribe/caller directory. Create\na new file named urls.py to contain routes for the caller app.\nAdd all of these lines to the empty djtranscribe/caller/urls.py\nfile.\n# djtranscribe/caller/urls.py\nfrom django.conf.urls import url\nfrom . import views\n\nurlpatterns = [\n    url(r'', views.index, name=\"index\"),\n]\n\nSave djtranscribe/caller/urls.py. Open\ndjtranscribe/caller/views.py to add the\nfollowing two highlighted lines. \n# djtranscribe/caller/views.py\nfrom django.http import HttpResponse def index(request):\n return HttpResponse('Hello, world!', 200)\n\nWe can test out that this simple boilerplate response is\ncorrect before we start adding the meat of the functionality to\nthe project. Change into the base directory of your Django project\nwhere the manage.py file is located. Execute the development\nserver with the following command:\npython manage.py runserver\n\nThe Django development server should start up with no issues other than\nan unapplied migrations warning.\nWatching for file changes with StatReloader\nPerforming system checks... System check identified no issues (0 silenced). November 15, 2020 - 14:07:03\nDjango version 3.1.3, using settings 'djtranscribe.settings'\nStarting development server at http://127.0.0.1:8000/\nQuit the server with CONTROL-C.\n\nOpen a web browser and go to localhost:8000.\n\nYou should see 'Hello, world!' rendered in the browser.\nThat means everything is working properly so far and we can\nnow add the dialing, recording and transcribing capabilities to\nour Django project.\nAdding Twilio to the Django project\nTime to add Twilio's Voice API into the mix so we can dial\na phone call from our Django project and make a recording\nout of it.\nStart by opening up djtranscribe/djtranscribe/settings.py\nand modifying it with the following highlighted import os\nline:\n# djtranscribe/djtranscribe/settings.py\nimport os\nfrom pathlib import Path\n\n\n# Build paths inside the project like this: BASE_DIR / 'subdir'.\nBASE_DIR = Path(__file__).resolve().parent.parent\n\nThen at the bottom of the settings.py file, add the\nfollowing highlighted lines, which will be settings that are pulled from\nenvironment variables we will configure later.\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/3.1/howto/static-files/ STATIC_URL = '/static/' BASE_URL = os.getenv(\"BASE_URL\")\nTWIML_INSTRUCTIONS_URL = \"{}/record/\".format(BASE_URL)\nTWILIO_PHONE_NUMBER = os.getenv(\"TWILIO_PHONE_NUMBER\")\n\nSave settings.py and change into the caller Django app directory.\nUpdate djtranscribe/caller/urls.py with the the following new\ncode:\n# djtranscribe/caller/urls.py\nfrom django.conf.urls import url from . import views urlpatterns = [  url(r'dial/(\\d+)/$', views.dial, name=\"dial\"),\n url(r'record/$', views.record_twiml, name=\"record-twiml\"),\n url(r'get-recording-url/([A-Za-z0-9]+)/$', views.get_recording_url,\n name='recording-url'),\n]\n\nNext, open djtranscribe/views.py and update it with the following\ncode, replacing what already exists within the file:\n# djtranscribe/caller/views.py\nfrom django.conf import settings\nfrom django.http import HttpResponse\nfrom django.views.decorators.csrf import csrf_exempt from twilio.rest import Client\nfrom twilio.twiml.voice_response import VoiceResponse def dial(request, phone_number): \"\"\"Dials an outbound phone call to the number in the URL. Just as a heads up you will never want to leave a URL like this exposed without authentication and further phone number format verification. phone_number should be just the digits with the country code first, for example 14155559812.\"\"\" # pulls credentials from environment variables twilio_client = Client() call = twilio_client.calls.create( to='+{}'.format(phone_number), from_=settings.TWILIO_PHONE_NUMBER, url=settings.TWIML_INSTRUCTIONS_URL, ) print(call.sid) return HttpResponse(\"dialing +{}. call SID is: {}\".format( phone_number, call.sid)) @csrf_exempt\ndef record_twiml(request): \"\"\"Returns TwiML which prompts the caller to record a message\"\"\" # Start our TwiML response response = VoiceResponse() # Use <Say> to give the caller some instructions response.say('Ahoy! Call recording starts now.') # Use <Record> to record the caller's message response.record() # End the call with <Hangup> response.hangup() return HttpResponse(str(response), content_type='application/xml') def get_recording_url(request, call_sid): \"\"\"Returns an HttpResponse with plain text of the link to one or more recordings from the specified Call SID.\"\"\" # pulls credentials from environment variables twilio_client = Client() recording_urls = \"\" call = twilio_client.calls.get(call_sid) for r in call.recordings.list(): recording_urls=\"\\n\".join([recording_urls, \"\".join(['https://api.twilio.com', r.uri])])\n    return HttpResponse(str(recording_urls), 200)\n\nEach of the above view functions performs one of the steps needed to\ncreate a call recording of a phone call dialed by Twilio, and then\nretrieve it as a file. dial programmatically initiates the outbound\ncall, record_twiml returns instructions to play a message that the\ncall is being recorded, records it, and then hangs up when the call\nis done. get_recording_url only returns the URL location of the\nrecorded phone call so that in the next step we can send the file over\nto AssemblyAI.\nOur Django project modifications are done. Next, we need to use\ntwo services, Twilio and Ngrok, to enable some of the machine\nto happen of phone calling and running the application from our\nlocal machine.\nTwilio credentials and environment variables\nSign up for Twilio or\nlog into your existing account.\nOnce you get to the Twilio Console,\nyou can obtain your TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN on the\nright side of the page:\n\nWhen you sign up you should have a phone number assigned to your account.\nYou can use that or\npurchase a new phone number\nto use.\nSet three environment variables with the names TWILIO_ACCOUNT_SID,\nTWILIO_AUTH_TOKEN, and TWILIO_PHONE_NUMBER using the export command\nin your terminal. Make sure to replace the values with your own Account SID,\nAuth Token and Twilio phone number.\nexport TWILIO_ACCOUNT_SID=xxxxxxxxxxxxx # found in twilio.com/console\nexport TWILIO_AUTH_TOKEN=yyyyyyyyyyyyyy # found in twilio.com/console\nexport TWILIO_PHONE_NUMBER=+17166382453    # replace with your Twilio number\n\nNote that you must use the export command in every command line window\nthat you want this key to be accessible. The scripts we are writing will\nnot be able to access the Twilio APIs if you do not have the tokens exported\nin the environment where you are running the script.\nThere is one more environment variable to set before we can run app.py.\nWe need to use Ngrok as a localhost tunnel so that Twilio's webhook can\nsend an HTTP POST request to our Django application running on\nour local development environment.\nRun Ngrok in a new terminal window, because you will need to keep it\nrunning while we run our other Python code: \nCopy the HTTPS version of the \"Forwarding\" URL and set the BASE_URL\nenvironment variable value to it. For example, in this screenshot you\nwould set BASE_URL to https://7764c1810ad3.ngrok.io using the\nfollowing command:\nexport BASE_URL=https://7764c1810ad3.ngrok.io    # use your ngrok URL, or domain. no trailing slash\n\nWe also need to update djtranscribe/djtranscribe/settings.py's\nALLOWED_HOSTS list to include the Ngrok Forwarding URL otherwise\nthe webhook from Twilio asking for instructions\non how to handle the phone call will fail. Open the settings.py\nfile and update the ALLOWED_HOSTS with your Ngrok Forwarding\nhostname list the following:\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = os.getenv('SECRET_KEY', 'development key') # SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True ALLOWED_HOSTS = ['7764c1810ad3.ngrok.io','127.0.0.1','localhost'] # Application definition INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'caller',\n]\n\nOkay, we can finally re-run our Django web app. Ensure Ngrok is still\nrunning in a different window, your virtualenv is active and that in this\nterminal you have your four environment variables set, then run the\nrunserver command in the root project directory where manage.py\nis located:\npython manage.py runserver\n\nLet's make our phone ring by testing the application.\nTesting Twilio Programmable Voice Recording\nWe can test our application by going to localhost on port 8000.\nGo to this URL in your web browser, replacing the \"14155551234\"\nwith the phone number you want to call, where the person on the\nline will be recorded: http://localhost:8000/dial/14155551234.\nThat number should now receive a phone call from your Twilio\nnumber. Pick up, record a message that you want to use to test\nthe transcription, and then hang up.\nIf you get an error, make sure all of your environment variables\nare set. You can check the values by using the echo command like\nthis: When the call is over, copy the call SID show on the web page\nso that we can use it to look up where the recording audio\nfile is stored.\n\nGo to \"localhost:8000/get-recording-url/\" with the call SID\nat the end. For example,\n\"localhost:8000/get-recording-url/CAda3f2f49ff4e8ef2be6b726edb998c92\".\n\nCopy the entire output except for the \".json\" at the end, then paste\nit into the web browser's URL bar, prepended with \"api.twilio.com\".\nFor example,\n\"https://api.twilio.com/2010-04-01/Accounts/ACe3737affa0d2e17561ad44c9d190e70c/Recordings/RE3b42cf470bef829c3680ded961a09300\".\nThis will bring up the recording. Copy the entire URL and we will use it\nas input into the AssemblyAI service.\nTranscribing with the AssemblyAI API\nWe can now use the AssemblyAI API for speech-to-text transcription on\nthe call recording that was just made.\nSign up for an AssemblyAI account\nand log in to the\nAssemblyAI dashboard, then\ncopy \"Your API token\" as shown in this screenshot:\n\nWe need to export our AssemblyAI API key as an environment variable\nso that our Python application can use it to authenticate with their\nAPI. We also need to pass the publicly-accessible URL for the recording,\nso we'll set that as an environment variable as well.\n# make sure to replace this URL with the one for your recording\nexport ASSEMBLYAI_KEY=your-api-key-here\nexport RECORDING_URL=https://api.twilio.com/2010-04-01/Accounts/ACe3737affa0d2e17561ad44c9d190e70c/Recordings/RE3b42cf470bef829c3680ded961a09300\n\nCreate a new file named transcribe.py and write the following code in it:\nimport os\nimport requests\n\nendpoint = \"https://api.assemblyai.com/v2/transcript\"\n\njson = {\n  \"audio_url\": os.getenv(\"RECORDING_URL\")\n}\n\nheaders = {\n    \"authorization\": os.getenv(\"ASSEMBLYAI_KEY\"),\n    \"content-type\": \"application/json\"\n}\n\nresponse = requests.post(endpoint, json=json, headers=headers)\n\nprint(response.json())\n\nThe above code calls the AssemblyAI transcription service using\nthe secret key and passes it the URL with the file recording.\nThe script prints out the JSON response from the service,\nwhich will contain a transcription ID that we'll use to access\nthe results after they finish processing.\nRun the script using the python command: You will get back some JSON as output, similar what you see here:\n{'audio_end_at': None, 'acoustic_model': 'assemblyai_default', 'text': None, 'audio_url': 'https://api.twilio.com/2010-04-01/Accounts/ACe3737affa0d2e17561ad44c9d190e70c/Recordings/RE3b42cf470bef829c3680ded961a09300', 'speed_boost': False, 'language_model': 'assemblyai_default', 'redact_pii': False, 'confidence': None, 'webhook_status_code': None, 'id': 'zibe9vwmx-82ce-476c-85a7-e82c09c67daf', 'status': 'queued',\n'boost_param': None, 'words': None, 'format_text': True, 'webhook_url': None, 'punctuate': True, 'utterances': None, 'audio_duration': None, 'auto_highlights': False, 'word_boost': [], 'dual_channel': None, 'audio_start_from': None}\n\nFind the value contained with the id field of the JSON response. We need\nthat value to look up the final result of our transcription. Copy the\ntranscription ID and set it as an environment variable to use as input by\nthe final script:\n# replace with what's found within `id` from the JSON response\nexport TRANSCRIPTION_ID=aksd19vwmx-82ce-476c-85a7-e82c09c67daf\n\nWe just need a little more Python that looks up the result and we'll be all\ndone.\nRetrieve the AssemblyAI Transcription\nAssemblyAI will be busy transcribing the recording. Depending on the size of\nthe file it can take anywhere from a few seconds to a few minutes for the\njob to complete. We can use the following code to see if the job is still\nin progress or it has completed. If the transcription is done it will print\nthe results to the terminal.\nCreate a new file named print_transcription.py with the following code:\nimport os\nimport requests endpoint = \"https://api.assemblyai.com/v2/transcript/{}\".format(os.getenv(\"TRANSCRIPTION_ID\")) headers = { \"authorization\": os.getenv(\"ASSEMBLYAI_KEY\"),\n} response = requests.get(endpoint, headers=headers) print(response.json())\nprint(\"\\n\\n\")\nprint(response.json()['text'])\n\nThe code above in print_transcription.py is very similar to the code\nin the previous transcribe.py source file. imports os (operating system)\nfrom the Python standard library, as we did in the previous two files,\nto obtain the TRANSCRIPTION_ID and ASSEMBLYAI_KEY environment variable\nvalues.\nThe endpoint is the AssemblyAI API endpoint for retrieving\ntranscriptions. We set the appropriate authorization header and\nmake the API call using the requests.get function. We then print\nout the JSON response as well as just the text that was transcribed.\nTime to test out this third file. Execute the following command in\nthe terminal:\npython print_transcription.py\n\nYour output will be different based on your recording but you should see a\nresult in the terminal similar to the following:\n{'audio_end_at': None, 'acoustic_model': 'assemblyai_default', 'auto_highlights_result': None, 'text': 'An object relational mapper is a code library that automates the transfer of data stored in a relational database tables into objects that are more commonly used in application. Code or MS provide a high level abstraction upon a relational database that allows the developer to write Python code. Instead of sequel to create read update and delete data and schemas in their database developers can use the programming language that they are comfortable with comfortable to work with the database instead of writing sequel statements or short procedures.', 'audio_url': 'https://api.twilio.com/2010-04-01/Accounts/ACe3737affa0d2e17561ad44c9d190e70c/Recordings/RE3b42cf470bef829c3680ded961a09300', 'speed_boost': False, 'language_model': 'assemblyai_default', 'id': 'zibe9vwmx-82ce-476c-85a7-e82c09c67daf', 'confidence': 0.931797752808989, 'webhook_status_code': None, 'status': 'completed', 'boost_param': None, 'redact_pii': False, 'words': [{'text': 'An', 'confidence': 1.0, 'end': 90, 'start': 0}, {'text': 'object', 'confidence': 0.94, 'end': 570, 'start': 210}, {'text': 'relational', 'confidence': 0.89, 'end': 1080, 'start': 510}, {'text': 'mapper', 'confidence': 0.97, 'end': 1380, 'start': 1020}, {'text': 'is', 'confidence': 0.88, 'end': 1560, 'start': 1350}, {'text': 'a', 'confidence': 0.99, 'end': 1620, 'start': 1500}, {'text': 'code', 'confidence': 0.93, 'end': 1920, 'start': 1620}, {'text': 'library', 'confidence': 0.94, 'end': 2250, 'start': 1860}, {'text': 'that', 'confidence': 0.99, 'end': 2490, 'start': 2220}, {'text': 'automates', 'confidence': 0.93, 'end': 2940, 'start': 2430}, {'text': 'the', 'confidence': 0.95, 'end': 3150, 'start': 2910}, {'text': 'transfer', 'confidence': 0.98, 'end': 3510, 'start': 3090}, {'text': 'of', 'confidence':\n0.99, 'end': 3660, 'start': 3480}, {'text': 'data', 'confidence': 0.84, 'end': 3960, 'start': 3630}, {'text': 'stored', 'confidence': 0.89, 'end': 4350, 'start': 3900}, {'text': 'in', 'confidence': 0.98, 'end': 4500, 'start': 4290}, {'text': 'a', 'confidence': 0.85, 'end': 4560, 'start': 4440}, {'text': 'relational', 'confidence': 0.87, 'end': 5580, 'start': 4500}, {'text': 'database', 'confidence': 0.92, 'end':\n6030, 'start': 5520}, {'text': 'tables', 'confidence': 0.93, 'end': 6330, 'start': 5970}, {'text': 'into', 'confidence': 0.92, 'end': 7130, 'start': 6560}, {'text': 'objects', 'confidence': 0.96, 'end': 7490, 'start': 7100}, {'text': 'that', 'confidence': 0.97, 'end': 7700, 'start': 7430}, {'text': 'are', 'confidence': 0.9, 'end': 7850, 'start': 7640}, {'text': 'more', 'confidence': 0.97, 'end': 8030, 'start': 7790}, {'text': 'commonly', 'confidence': 0.92, 'end': 8480, 'start': 7970}, {'text': 'used', 'confidence': 0.86, 'end': 8750, 'start': 8420}, {'text': 'in', 'confidence': 0.94, 'end': 9050, 'start': 8840}, {'text': 'application.', 'confidence': 0.98, 'end': 9860, 'start': 9110}, {'text': 'Code', 'confidence': 0.93, 'end': 10040, 'start': 9830}, {'text': 'or', 'confidence': 1.0, 'end': 11210, 'start': 10220}, {'text': 'MS', 'confidence': 0.83, 'end': 11480, 'start': 11180}, {'text': 'provide', 'confidence': 0.94, 'end': 11870, 'start': 11510}, {'text': 'a', 'confidence': 1.0, 'end': 11960, 'start': 11840}, {'text': 'high', 'confidence': 1.0, 'end': 12200, 'start': 11930}, {'text': 'level', 'confidence': 0.94, 'end': 12440, 'start': 12170}, {'text': 'abstraction', 'confidence': 0.95, 'end': 12980, 'start': 12410}, {'text':\n'upon', 'confidence': 0.94, 'end': 13220, 'start': 12950}, {'text': 'a', 'confidence': 1.0, 'end': 13280, 'start': 13160}, {'text': 'relational', 'confidence': 0.94, 'end': 13820, 'start': 13280}, {'text': 'database', 'confidence': 0.95, 'end': 14210, 'start': 13790}, {'text': 'that', 'confidence': 0.96, 'end': 14420, 'start': 14150}, {'text': 'allows', 'confidence': 0.99, 'end': 14720, 'start': 14360}, {'text':\n'the', 'confidence': 0.56, 'end': 14870, 'start': 14690}, {'text': 'developer', 'confidence': 0.98, 'end': 15290, 'start': 14810}, {'text': 'to', 'confidence': 0.94, 'end': 15410, 'start': 15230}, {'text': 'write', 'confidence': 0.96, 'end': 15680, 'start': 15380}, {'text': 'Python', 'confidence': 0.94, 'end': 16070, 'start': 15620}, {'text': 'code.', 'confidence': 0.98, 'end': 16310, 'start': 16070}, {'text': 'Instead', 'confidence': 0.97, 'end': 17160, 'start': 16500}, {'text': 'of', 'confidence': 0.93, 'end': 17340, 'start': 17130}, {'text': 'sequel', 'confidence': 0.86, 'end': 17820, 'start': 17280}, {'text': 'to', 'confidence': 0.91, 'end': 18090, 'start': 17880}, {'text': 'create', 'confidence': 0.89, 'end': 18450, 'start': 18090}, {'text': 'read', 'confidence': 0.88, 'end': 18840, 'start': 18480}, {'text': 'update', 'confidence': 0.92, 'end': 19290, 'start': 18870}, {'text': 'and', 'confidence': 0.94, 'end': 19590, 'start': 19230}, {'text': 'delete', 'confidence': 0.89, 'end': 19920, 'start': 19530}, {'text': 'data',\n'confidence': 0.95, 'end': 20190, 'start': 19890}, {'text': 'and', 'confidence': 0.92, 'end': 20490, 'start': 20250}, {'text': 'schemas', 'confidence': 0.86, 'end': 21000, 'start': 20430}, {'text': 'in', 'confidence': 0.94, 'end': 21210, 'start': 21000}, {'text': 'their', 'confidence': 0.98, 'end': 21510, 'start': 21150}, {'text': 'database', 'confidence': 0.97, 'end': 21900, 'start': 21450}, {'text': 'developers', 'confidence': 0.83, 'end': 23200, 'start': 22420}, {'text': 'can', 'confidence': 0.95, 'end': 23440, 'start': 23200}, {'text': 'use', 'confidence': 0.97, 'end': 23650, 'start': 23410}, {'text': 'the', 'confidence': 0.99, 'end': 23890, 'start': 23590}, {'text': 'programming', 'confidence': 0.97, 'end': 24370, 'start': 23830}, {'text': 'language', 'confidence': 1.0, 'end': 24700, 'start': 24310}, {'text': 'that', 'confidence': 1.0, 'end': 24880, 'start': 24640}, {'text': 'they', 'confidence': 0.99, 'end': 25060, 'start': 24820}, {'text': 'are', 'confidence': 0.85, 'end': 25210, 'start': 25000}, {'text': 'comfortable', 'confidence': 0.92, 'end': 25780, 'start': 25180}, {'text': 'with', 'confidence': 1.0, 'end': 25960, 'start': 25720}, {'text': 'comfortable', 'confidence': 0.94, 'end': 29090, 'start': 28090}, {'text': 'to', 'confidence': 0.84, 'end': 29840, 'start': 29180}, {'text': 'work', 'confidence': 0.95, 'end': 30050, 'start': 29780}, {'text': 'with', 'confidence': 0.98, 'end': 30290, 'start': 30020}, {'text': 'the', 'confidence': 0.69, 'end': 30440, 'start': 30230}, {'text': 'database', 'confidence': 0.98, 'end': 30860, 'start': 30380}, {'text': 'instead', 'confidence': 1.0, 'end': 32780, 'start': 31780}, {'text': 'of', 'confidence': 0.98, 'end': 32900, 'start': 32720}, {'text': 'writing', 'confidence': 0.87, 'end': 33320, 'start': 32870}, {'text': 'sequel', 'confidence': 0.88, 'end': 33860, 'start': 33290}, {'text': 'statements', 'confidence': 0.95, 'end': 34310, 'start': 33800}, {'text': 'or', 'confidence': 0.9, 'end': 34460, 'start': 34250}, {'text': 'short', 'confidence': 0.9, 'end': 34790, 'start': 34430}, {'text': 'procedures.', 'confidence': 0.98, 'end': 35270, 'start': 34760}], 'format_text': True, 'webhook_url': None, 'punctuate': True, 'utterances': None, 'audio_duration': 36.288, 'auto_highlights': False, 'word_boost': [],\n'dual_channel': None, 'audio_start_from': None}\n\n\nAn object relational mapper is a code library that automates the transfer of data stored in a relational database tables into objects that are more commonly used in application. Code or MS provide a high level abstraction upon a relational database that allows the developer to write Python code. Instead of sequel to create read update and delete data and schemas in their database developers can use the programming language that they are comfortable with comfortable to work with the database instead of writing sequel statements or short procedures.\n\nThat's a lot of output. The first part contains the results of the\ntranscription and the confidence in the accuracy of each word transcribed.\nThe second part is just the plain text output from the transcription.\nYou can take this now take this base code and add it to any application\nthat needs high quality text-to-speech transcription. If the results\naren't quite good enough for you yet, check out this tutorial on\nboosting accuracy for keywords or phrases.\nAdditional resources\nWe just finished building a highly accurate transcription application for recordings.\nNext, try out some of these other related Django tutorials: Questions? Let me know via\na GitHub issue ticket on the Full Stack Python repository,\non Twitter\n@fullstackpython\nor @mattmakai.\nSee something wrong with this post? Fork\nthis page's source on GitHub\nand submit a pull request.\n",
        "next_page_url":null,
        "url":"https://www.fullstackpython.com/blog/django-accurate-twilio-voice-transcriptions.html",
        "domain":"www.fullstackpython.com",
        "excerpt":"Use Python, Django and AssemblyAI's transcription API to improve recording accuracy for Twilio Programmable Voice phone calls. Great post on fullstackpython.com!",
        "word_count":3783,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     },
     {
        "title":"Writing more concise code",
        "author":null,
        "date_published":null,
        "dek":null,
        "lead_image_url":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1648852528720%2FQAU8Bv7uq.png%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng",
        "content":"Note: This article assumes existing knowledge of Python 🐍\nIf you've ever written an if statement with a bunch of conditions based on a users input, then you know how tedious it is. You can solve this problem with a dictionary. def greet(): print(f\"Hello!\") def greet_formal(): print(f\"A very good day to you\")\n\n\n\nWe're defining two functions, greet() and greet_formal() to call later, depending on user input. action = input(\"What would you like to do? \\n1. Greet a person \\n2. Greet a person formally\\n\")\n\nThe \\n is going to print the rest of the string on a new line. Our input would be shown to the user like this: \nWhat would you like to do?\n1. Greet a person\n2. Greet a person formally\n# waits for input...\n\nactions = { '1': greet, '2': greet_formal\n}\n\nWe create a python dictionary that has as the keys what we expect the user to enter, and for the values, we have the function names. Notice that there are no parentheses after the function names. If we included them, then Python would execute both functions when we run the file. Normally, you might do something like this:\nif action == '1': greet()\nelif action == '2': greet_formal()\nelse: print(\"Sorry, that isn't a valid choice\")\n\nObviously, it's not that terrible when you only have two functions, but if you have a bunch of options, it could really slow you down. A much faster way to do it is like this:\nactions[action]()\n\nThis might look a little confusing so let me explain.\nLet's say the user entered 1 as their choice. actions[action] would get whatever we set '1' to in the actions dict, which, in this case, is the greet function. Remember before when we didn't include the parentheses because we didn't want to call it? Now, we do want to call it so we include the parentheses after the function name and call the function.\n",
        "next_page_url":null,
        "url":"https://codewithisrael.hashnode.dev/writing-more-concise-code",
        "domain":"codewithisrael.hashnode.dev",
        "excerpt":"How to write less if/else statements",
        "word_count":320,
        "direction":"ltr",
        "total_pages":1,
        "rendered_pages":1
     }
]